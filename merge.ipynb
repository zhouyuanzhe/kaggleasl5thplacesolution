{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-04-18T02:17:52.903077Z","iopub.status.busy":"2023-04-18T02:17:52.902562Z","iopub.status.idle":"2023-04-18T02:17:52.910016Z","shell.execute_reply":"2023-04-18T02:17:52.908529Z","shell.execute_reply.started":"2023-04-18T02:17:52.903035Z"},"papermill":{"duration":0.022789,"end_time":"2023-04-17T09:25:56.726300","exception":false,"start_time":"2023-04-17T09:25:56.703511","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:17:52.916824Z","iopub.status.busy":"2023-04-18T02:17:52.915589Z","iopub.status.idle":"2023-04-18T02:17:52.925114Z","shell.execute_reply":"2023-04-18T02:17:52.924165Z","shell.execute_reply.started":"2023-04-18T02:17:52.916778Z"},"papermill":{"duration":11.575442,"end_time":"2023-04-17T09:26:08.307736","exception":false,"start_time":"2023-04-17T09:25:56.732294","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-05-03 11:10:41.870806: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-03 11:10:41.995600: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-05-03 11:10:42.683461: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/zhouyuanzhe/hxdoc:\n","2023-05-03 11:10:42.683554: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/zhouyuanzhe/hxdoc:\n","2023-05-03 11:10:42.683560: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["import sys \n","import argparse\n","import logging\n","import os\n","import pickle\n","import random\n","import torch\n","import json\n","import numpy as np\n","import pandas as pd\n","from torch.nn import CrossEntropyLoss, MSELoss\n","from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler,TensorDataset\n","from transformers import (WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup,BertConfig,BertModel, AlbertConfig, AlbertModel,DebertaV2Config,DebertaV2Model,\n","                              RobertaConfig, RobertaModel, RobertaTokenizer)\n","from sklearn.model_selection import GroupKFold,StratifiedGroupKFold\n","import torch.nn as nn\n","from tqdm import tqdm\n","import torch.nn.functional as F\n","import math\n","from collections import defaultdict\n","from itertools import chain\n","from torch.optim import Optimizer\n","import torch\n","import warnings"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:17:53.046483Z","iopub.status.busy":"2023-04-18T02:17:53.045727Z","iopub.status.idle":"2023-04-18T02:17:53.104803Z","shell.execute_reply":"2023-04-18T02:17:53.103484Z","shell.execute_reply.started":"2023-04-18T02:17:53.046441Z"},"papermill":{"duration":0.332154,"end_time":"2023-04-17T09:26:08.645867","exception":false,"start_time":"2023-04-17T09:26:08.313713","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["label_smoothing = 0.75\n","num_class  = 250\n","num_landmark = 543\n","max_length = 256\n","# point_dim  = 1323\n","embed_dim  = 240\n","num_head   = 16\n","num_block  = 3\n","root_dir = '.'\n","\n","LHAND = np.arange(468, 489).tolist() # 21\n","RHAND = np.arange(522, 543).tolist() # 21\n","POSE  = np.arange(489, 522).tolist() # 33\n","FACE  = np.arange(0,468).tolist()    #468\n","\n","REYE = [\n","    33, 7, 163, 144, 145, 153, 154, 155, 133,\n","    246, 161, 160, 159, 158, 157, 173,\n","][::2]\n","LEYE = [\n","    263, 249, 390, 373, 374, 380, 381, 382, 362,\n","    466, 388, 387, 386, 385, 384, 398,\n","][::2]\n","NOSE=[\n","    1,2,98,327\n","]\n","SLIP = [\n","    78, 95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n","    191, 80, 81, 82, 13, 312, 311, 310, 415,\n","]\n","SPOSE = (np.array([\n","    11,13,15,12,14,16,23,24,\n","])+489).tolist()\n","\n","BODY = REYE+LEYE+NOSE+SLIP+SPOSE\n","\n","def get_indexs(L):\n","    return sorted([i + j * len(L) for i in range(len(L)) for j in range(len(L)) if i>j])\n","\n","DIST_INDEX = get_indexs(RHAND)\n","\n","LIP_DIST_INDEX = get_indexs(SLIP)\n","\n","POSE_DIST_INDEX = get_indexs(SPOSE)\n","\n","EYE_DIST_INDEX = get_indexs(REYE)\n","\n","NOSE_DIST_INDEX = get_indexs(NOSE)\n","\n","HAND_START = [0,1,2,3,5,6,7,9,10,11,13,14,15,17,18,19,0,5,9,13,0]\n","HAND_END = [1,2,3,4,6,7,8,10,11,12,14,15,16,18,19,20,5,9,13,17,17]\n","\n","point_dim = point_dim2 = len(LHAND+RHAND+REYE+LEYE+NOSE+SLIP+SPOSE)*2+len(LHAND+RHAND)*2+len(RHAND)+len(DIST_INDEX)*2+len(EYE_DIST_INDEX)*2+len(LIP_DIST_INDEX)+len(POSE_DIST_INDEX)\n","\n","def pack_seq(\n","\tseq,\n","):\n","\tlength = [min(len(s), max_length)  for s in seq]\n","\tbatch_size = len(seq)\n","\tK = seq[0].shape[1]\n","\tL = max(length)\n","\t#print(length)\n","\n","\tx = torch.zeros((batch_size, L, point_dim))#.to(seq[0].device)\n","\tx_mask = torch.zeros((batch_size, L))#.to(seq[0].device)\n","\tfor b in range(batch_size):\n","\t\tl = length[b]\n","\t\tx[b, :l] = seq[b][:l,:]\n","\t\tx_mask[b, l:] = 1\n","\tx_mask = (x_mask>0.5)\n","\n","\treturn x, x_mask\n","\n","def positional_encoding(length, embed_dim):\n","\tdim = embed_dim//2\n","\tposition = np.arange(length)[:, np.newaxis]     # (seq, 1)\n","\tdim = np.arange(dim)[np.newaxis, :]/dim   # (1, dim)\n","\tangle = 1 / (10000**dim)         # (1, dim)\n","\tangle = position * angle    # (pos, dim)\n","\tpos_embed = np.concatenate(\n","\t\t[np.sin(angle), np.cos(angle)],\n","\t\taxis=-1\n","\t)\n","\tpos_embed = torch.from_numpy(pos_embed).float()\n","\treturn pos_embed\n","\n","class FCLayer(nn.Module):\n","    def __init__(self, embed_dim, hidden_dim, split=4):\n","        super().__init__()\n","        self.dim = embed_dim//4\n","        self.mlp = nn.ModuleList(\n","            [nn.Linear(embed_dim//4, hidden_dim//4) for i in range(split)]\n","        )\n","        self.split=split\n","    def forward(self, x):\n","        output = []\n","        for i in range(self.split):\n","            output.append(self.mlp[i](x[:,:,self.dim*i:self.dim*i+self.dim]))\n","        x = torch.cat(output, -1)\n","        return x\n","\n","class TransformerBlock(nn.Module):\n","\tdef __init__(self,\n","\t    embed_dim,\n","        num_head,\n","        out_dim,\n","\t):\n","\t\tsuper().__init__()\n","\t\tself.attn  = MyMultiHeadAttention(\n","\t\t\tembed_dim=embed_dim,\n","\t\t\tout_dim=embed_dim,\n","\t\t\tqk_dim=embed_dim // num_head,\n","\t\t\tv_dim=embed_dim // num_head,\n","\t\t\tnum_head=num_head,\n","\n","\t\t)\n","\t\tself.ffn   = FeedForward(embed_dim, out_dim*2)\n","\t\tself.norm1 = nn.LayerNorm(embed_dim)\n","\t\tself.norm2 = nn.LayerNorm(out_dim)\n","\n","\tdef forward(self, x, x_mask=None):\n","\t\tx = x + self.attn((self.norm1(x)), x_mask)\n","\t\tx = x + self.ffn((self.norm2(x)))\n","\t\treturn x\n","    \n","class MyMultiHeadAttention(nn.Module):\n","\tdef __init__(self,\n","\t\t\tembed_dim,\n","\t\t\tout_dim,\n","\t\t\tqk_dim,\n","\t\t\tv_dim,\n","\t\t\tnum_head,\n","\t\t):\n","\t\tsuper().__init__()\n","\t\tself.embed_dim = embed_dim\n","\t\tself.num_head  = num_head\n","\t\tself.qk_dim = qk_dim\n","\t\tself.v_dim  = v_dim\n","\n","\t\tself.q = nn.Linear(embed_dim, qk_dim*num_head)\n","\t\tself.k = nn.Linear(embed_dim, qk_dim*num_head)\n","\t\tself.v = nn.Linear(embed_dim, v_dim*num_head)\n","\n","\t\tself.out = nn.Linear(v_dim*num_head, out_dim)\n","\t\tself.scale = 1/(qk_dim**0.5)\n","\n","\t#https://github.com/pytorch/pytorch/issues/40497\n","\tdef forward(self, x, x_mask):\n","\t\tB,L,dim = x.shape\n","\t\t#out, _ = self.mha(x,x,x, key_padding_mask=x_mask)\n","\t\tnum_head = self.num_head\n","\t\tqk_dim = self.qk_dim\n","\t\tv_dim = self.v_dim\n","\n","\t\tq = self.q(x)\n","\t\tk = self.k(x)\n","\t\tv = self.v(x)\n","\t\tq = q.reshape(B, L, num_head, qk_dim).permute(0,2,1,3).contiguous()\n","\t\tk = k.reshape(B, L, num_head, qk_dim).permute(0,2,3,1).contiguous()\n","\t\tv = v.reshape(B, L, num_head, v_dim ).permute(0,2,1,3).contiguous()\n","\n","\t\tdot = torch.matmul(q, k) *self.scale  # H L L\n","\t\tx_mask = x_mask.reshape(B,1,1,L).expand(-1,num_head,L,-1)\n","\t\t#dot[x_mask]= -1e4\n","\t\tdot.masked_fill_(x_mask, -1e4)\n","\t\tattn = F.softmax(dot, -1)    # L L\n","\n","\t\tv = torch.matmul(attn, v)  # L H dim\n","\t\tv = v.permute(0,2,1,3).reshape(B,L, v_dim*num_head).contiguous()\n","\t\tout = self.out(v)\n","\n","\t\treturn out\n","    \n","\n","class FeedForward(nn.Module):\n","\tdef __init__(self, embed_dim, hidden_dim):\n","\t\tsuper().__init__()\n","\t\tself.mlp = nn.Sequential(\n","\t\t\tnn.Linear(embed_dim, hidden_dim),\n","            # FCLayer(embed_dim, hidden_dim,4),\n","\t\t\tnn.ReLU(inplace=True),\n","            # FCLayer(embed_dim, hidden_dim,4),\n","\t\t\tnn.Linear(hidden_dim, embed_dim),\n","\t\t)\n","\tdef forward(self, x):\n","\t\treturn self.mlp(x)\n","\n","    "]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:17:53.125774Z","iopub.status.busy":"2023-04-18T02:17:53.124912Z","iopub.status.idle":"2023-04-18T02:17:53.141850Z","shell.execute_reply":"2023-04-18T02:17:53.140548Z","shell.execute_reply.started":"2023-04-18T02:17:53.125722Z"},"papermill":{"duration":0.017374,"end_time":"2023-04-17T09:26:08.689113","exception":false,"start_time":"2023-04-17T09:26:08.671739","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class InputNet(nn.Module):\n","    def __init__(self, ):\n","        super().__init__()\n","        self.max_length = max_length \n","  \n","    def forward(self, xyz):\n","        xyz = xyz - xyz[~torch.isnan(xyz)].mean(0,keepdim=True) #noramlisation to common maen\n","        xyz = xyz / xyz[~torch.isnan(xyz)].std(0, keepdim=True)\n","\n","        LIP = [\n","            78, 95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n","            191, 80, 81, 82, 13, 312, 311, 310, 415,\n","        ]\n","        #LHAND = np.arange(468, 489).tolist()\n","        #RHAND = np.arange(522, 543).tolist()\n","\n","        lip = xyz[:, LIP]\n","        lhand = xyz[:, 468:489]\n","        rhand = xyz[:, 522:543]\n","        xyz = torch.cat([  # (none, 82, 3)\n","            lip,\n","            lhand,\n","            rhand,\n","        ], 1)\n","        xyz[torch.isnan(xyz)] = 0\n","        x = xyz[:self.max_length]\n","        return x\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:17:53.145704Z","iopub.status.busy":"2023-04-18T02:17:53.145065Z","iopub.status.idle":"2023-04-18T02:17:53.177259Z","shell.execute_reply":"2023-04-18T02:17:53.175860Z","shell.execute_reply.started":"2023-04-18T02:17:53.145651Z"},"papermill":{"duration":0.030644,"end_time":"2023-04-17T09:26:08.725176","exception":false,"start_time":"2023-04-17T09:26:08.694532","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["\n","\n","#overwrite the model used in training ....\n","class MyMultiHeadAttention(nn.Module):\n","\tdef __init__(self,\n","\t\t\tembed_dim,\n","\t\t\tout_dim,\n","\t\t\tqk_dim,\n","\t\t\tv_dim,\n","\t\t\tnum_head,\n","\t\t):\n","\t\tsuper().__init__()\n","\t\tself.embed_dim = embed_dim\n","\t\tself.num_head  = num_head\n","\t\tself.qk_dim = qk_dim\n","\t\tself.v_dim  = v_dim\n","\n","\t\tself.q = nn.Linear(embed_dim, qk_dim*num_head)\n","\t\tself.k = nn.Linear(embed_dim, qk_dim*num_head)\n","\t\tself.v = nn.Linear(embed_dim, v_dim*num_head)\n","\n","\t\tself.out = nn.Linear(v_dim*num_head, out_dim)\n","\t\tself.scale = 1/(qk_dim**0.5)\n","\n","\t#https://github.com/pytorch/pytorch/issues/40497\n","\tdef forward(self, x):\n","\t\tB,L,dim = x.shape\n","\t\t#out, _ = self.mha(x,x,x, key_padding_mask=x_mask)\n","\t\tnum_head = self.num_head\n","\t\tqk_dim = self.qk_dim\n","\t\tv_dim = self.v_dim\n","\n","\t\tq = self.q(x)\n","\t\tk = self.k(x)\n","\t\tv = self.v(x)\n","\t\tq = q.reshape(B, L, num_head, qk_dim).permute(0,2,1,3).contiguous()\n","\t\tk = k.reshape(B, L, num_head, qk_dim).permute(0,2,3,1).contiguous()\n","\t\tv = v.reshape(B, L, num_head, v_dim ).permute(0,2,1,3).contiguous()\n","\n","\t\tdot = torch.matmul(q, k) *self.scale  # H L L\n","\t\t#x_mask = x_mask.reshape(B,1,1,L).expand(-1,num_head,L,-1)\n","\t\t#dot[x_mask]= -1e4\n","\t\t#dot.masked_fill_(x_mask, -1e4)\n","\t\tattn = F.softmax(dot, -1)    # L L\n","\n","\t\tv = torch.matmul(attn, v)  # L H dim\n","\t\tv = v.permute(0,2,1,3).reshape(B,L, v_dim*num_head).contiguous()\n","\t\tout = self.out(v)\n","\n","\t\treturn out\n","    \n","\n","# remove mask\n","class TransformerBlock2(nn.Module):\n","\tdef __init__(self,\n","\t    embed_dim,\n","        num_head,\n","        out_dim,\n","\t):\n","\t\tsuper().__init__()\n","\t\tself.attn  = MyMultiHeadAttention(\n","\t\t\tembed_dim=embed_dim,\n","\t\t\tout_dim=embed_dim,\n","\t\t\tqk_dim=embed_dim // num_head,\n","\t\t\tv_dim=embed_dim // num_head,\n","\t\t\tnum_head=num_head,\n","\n","\t\t)\n","\t\tself.ffn   = FeedForward(embed_dim, out_dim*2)\n","\t\tself.norm1 = nn.LayerNorm(embed_dim)\n","\t\tself.norm2 = nn.LayerNorm(out_dim)\n","\n","\tdef forward(self, x):\n","\t\tx = x + self.attn((self.norm1(x)))\n","\t\tx = x + self.ffn((self.norm2(x)))\n","\t\treturn x\n","\n","class TransformerBlock3(nn.Module):\n","\tdef __init__(self,\n","\t    embed_dim,\n","        num_head,\n","        out_dim,\n","\t):\n","\t\tsuper().__init__()\n","\t\tself.attn  = MyMultiHeadAttention(\n","\t\t\tembed_dim=embed_dim,\n","\t\t\tout_dim=embed_dim,\n","\t\t\tqk_dim=24, #embed_dim // num_head,\n","\t\t\tv_dim=24, #embed_dim // num_head,\n","\t\t\tnum_head=num_head,\n","\n","\t\t)\n","\t\tself.ffn   = FeedForward(embed_dim, out_dim*2)\n","\t\tself.norm1 = nn.LayerNorm(embed_dim)\n","\t\tself.norm2 = nn.LayerNorm(out_dim)\n","\n","\tdef forward(self, x):\n","\t\tx = x + self.attn((self.norm1(x)))\n","\t\tx = x + self.ffn((self.norm2(x)))\n","\t\treturn x\n","\n","class TransformerBlock(nn.Module):\n","\tdef __init__(self,\n","\t    embed_dim,\n","        num_head,\n","        out_dim,\n","\t):\n","\t\tsuper().__init__()\n","\t\tself.attn  = MyMultiHeadAttention(\n","\t\t\tembed_dim=embed_dim,\n","\t\t\tout_dim=embed_dim,\n","\t\t\tqk_dim=embed_dim // num_head,\n","\t\t\tv_dim=embed_dim // num_head,\n","\t\t\tnum_head=num_head,\n","\n","\t\t)\n","\t\tself.ffn   = FeedForward(embed_dim, out_dim*2)\n","\t\tself.norm1 = nn.LayerNorm(embed_dim)\n","\t\tself.norm2 = nn.LayerNorm(out_dim)\n","\n","\tdef forward(self, x):\n","\t\tx = x + self.attn((self.norm1(x)))\n","\t\tx = x + self.ffn((self.norm2(x)))\n","\t\treturn x\n","\n","class XEmbed(nn.Module):\n","    def __init__(self,):\n","        super().__init__()\n","        self.v = nn.Sequential(\n"," \t\t\tnn.Linear(point_dim, embed_dim*2, bias=True),\n"," \t\t\tnn.LayerNorm(embed_dim*2),\n"," \t\t\tnn.ReLU(inplace=True),\n"," \t\t\tnn.Linear(embed_dim*2, embed_dim, bias=True),\n"," \t\t\tnn.LayerNorm(embed_dim),\n"," \t\t\tnn.ReLU(inplace=True),\n"," \t\t)\n","    def forward(self, x):\n","        v = self.v(x)\n","        x = v\n","        return x\n","\n","\n","class XEmbed2(nn.Module):\n","    def __init__(self,):\n","        super().__init__()\n","        self.v = nn.Sequential(\n"," \t\t\tnn.Linear(point_dim, 480*2, bias=True),\n"," \t\t\tnn.LayerNorm(480*2),\n"," \t\t\tnn.ReLU(inplace=True),\n"," \t\t\tnn.Linear(480*2, 480, bias=True),\n"," \t\t\tnn.LayerNorm(480),\n"," \t\t\tnn.ReLU(inplace=True),\n"," \t\t)\n","    def forward(self, x):\n","        v = self.v(x)\n","        x = v\n","        return x\n","\n","class SingleNet(nn.Module):\n","\n","    def __init__(self, num_class=num_class):\n","        super().__init__()\n","        self.num_block = 3\n","        self.embed_dim = embed_dim\n","        self.num_head  = num_head\n","        self.max_length = max_length\n","        self.num_point = point_dim\n","\n","        pos_embed = positional_encoding(max_length, self.embed_dim)\n","        self.pos_embed = nn.Parameter(pos_embed)\n","\n","        self.cls_embed = nn.Parameter(torch.zeros((1, self.embed_dim)))\n","        self.x_embed = XEmbed()\n","\n","        self.encoder = nn.ModuleList([\n","            TransformerBlock(\n","                self.embed_dim,\n","                self.num_head,\n","                self.embed_dim\n","            ) for i in range(self.num_block)\n","        ])\n","        self.logit = nn.Linear(self.embed_dim, num_class)\n","\n","    def forward(self, xyz):\n","        L,D = xyz.shape\n","        xyz = xyz.reshape(1,L,D)\n","        \n","        x = self.x_embed(xyz)\n","        \n","        x = x + self.pos_embed[:L].reshape(1,L,embed_dim)\n","        x = torch.cat([\n","                self.cls_embed.reshape(1,1,embed_dim),\n","                x\n","            ],1)\n","\n","        #for block in self.encoder: x = block(x) #remove tflite loop\n","        x = self.encoder[0](x)\n","        x = self.encoder[1](x)\n","        x = self.encoder[2](x)\n","        \n","        logit = self.logit(x.mean(1))\n","        return logit\n","    \n","\n","def positional_encoding1(length, embed_dim):\n","\tdim = embed_dim//2\n","\tposition = np.arange(length)[:, np.newaxis]     # (seq, 1)\n","\tdim = np.arange(dim)[np.newaxis, :]/dim   # (1, dim)\n","\tangle = 1 / (500**dim)         # (1, dim)\n","\tangle = position * angle    # (pos, dim)\n","\tpos_embed = np.concatenate(\n","\t\t[np.sin(angle), np.cos(angle)],\n","\t\taxis=-1\n","\t)\n","\tpos_embed = torch.from_numpy(pos_embed).float()\n","\treturn pos_embed\n","\n","class SingleNet2(nn.Module):\n","\n","    def __init__(self, max_length):\n","        super().__init__()\n","        self.num_block = 3\n","        self.embed_dim = 480\n","        self.num_head  = 16\n","        self.max_length = max_length\n","        self.num_point = point_dim\n","\n","        pos_embed = positional_encoding(max_length, self.embed_dim)\n","        self.pos_embed = nn.Parameter(pos_embed)\n","\n","        self.cls_embed = nn.Parameter(torch.zeros((1, self.embed_dim)))\n","        self.x_embed = XEmbed2()\n","\n","        self.encoder = nn.ModuleList([\n","            TransformerBlock2(\n","                self.embed_dim,\n","                self.num_head,\n","                self.embed_dim\n","            ) for i in range(self.num_block)\n","        ])\n","        self.logit = nn.Linear(self.embed_dim, num_class)\n","\n","    def forward(self, xyz):\n","        L,D = xyz.shape\n","        xyz = xyz.reshape(1,L,D)\n","        \n","        x = self.x_embed(xyz)\n","        \n","        x = x + self.pos_embed[:L].reshape(1,L,self.embed_dim)\n","        x = torch.cat([\n","                self.cls_embed.reshape(1,1,self.embed_dim),\n","                x\n","            ],1)\n","\n","        #for block in self.encoder: x = block(x) #remove tflite loop\n","        x = self.encoder[0](x)\n","        x = self.encoder[1](x)\n","        x = self.encoder[2](x)\n","\n","        logit = self.logit(x.mean(1))\n","        return logit\n","    \n","class SingleNet3(nn.Module):\n","    def __init__(self, max_length):\n","        super().__init__()\n","        self.num_block = 3\n","        self.embed_dim = 512\n","        self.num_head  = 32\n","        self.max_length = max_length\n","        self.num_point = point_dim\n","\n","        pos_embed = positional_encoding1(max_length, self.embed_dim)\n","        self.pos_embed = nn.Parameter(pos_embed)\n","\n","        self.cls_embed = nn.Parameter(torch.zeros((1, self.embed_dim)))\n","        self.x_embed = XEmbed()\n","\n","        self.norm = nn.LayerNorm(self.embed_dim)\n","\n","        self.encoder = nn.ModuleList([\n","            TransformerBlock3(\n","                self.embed_dim,\n","                self.num_head,\n","                self.embed_dim\n","            ) for i in range(self.num_block)\n","        ])\n","        self.logit = nn.Linear(self.embed_dim, num_class)\n","\n","    def forward(self, xyz):\n","        L,D = xyz.shape\n","        xyz = xyz.reshape(1,L,D)\n","        \n","        x = self.x_embed(xyz)\n","        \n","        x = x + self.pos_embed[:L].reshape(1,L,self.embed_dim)\n","        x = self.norm(x)\n","        x = torch.cat([\n","                self.cls_embed.reshape(1,1,self.embed_dim),\n","                x\n","            ],1)\n","        #x = x.unsqueeze(1)\n","\n","        #for block in self.encoder: x = block(x) #remove tflite loop\n","        x = self.encoder[0](x)\n","        x = self.encoder[1](x)\n","        x = self.encoder[2](x)\n","        #x = F.dropout(x,p=0.4,training=False)\n","\n","        logit = self.logit(x.mean(1))\n","        return logit"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:17:53.180981Z","iopub.status.busy":"2023-04-18T02:17:53.180506Z","iopub.status.idle":"2023-04-18T02:17:53.195152Z","shell.execute_reply":"2023-04-18T02:17:53.193640Z","shell.execute_reply.started":"2023-04-18T02:17:53.180938Z"},"papermill":{"duration":0.016251,"end_time":"2023-04-17T09:26:08.765489","exception":false,"start_time":"2023-04-17T09:26:08.749238","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class FinalNet(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.m1 = SingleNet2(384)\n","        checkpoint_file1 = '/home/zhouyuanzhe/zhouplearn/asl/saved_models/checkpoint-best-score/val_all_3layerlessnoise9999smooth75bs128head16seef22222222moreaugchangedata_epoch_250.pth'\n","\n","        from collections import OrderedDict\n","        new_state_dict = OrderedDict()\n","        state_dict = torch.load(checkpoint_file1)['state_dict']\n","        for k, v in state_dict.items():\n","            new_state_dict[k.replace('module.','')] = v\n","        self.m1.load_state_dict(new_state_dict)\n","\n","\n","        self.m2 = SingleNet()\n","        checkpoint_file2 = '/home/zhouyuanzhe/zhouplearn/asl/saved_models/checkpoint-best-score/epoch_399.pth'\n","\n","        from collections import OrderedDict\n","        new_state_dict = OrderedDict()\n","        state_dict = torch.load(checkpoint_file2)['state_dict']\n","        for k, v in state_dict.items():\n","            new_state_dict[k.replace('module.','')] = v\n","        self.m2.load_state_dict(new_state_dict)\n","\n","\n","    def forward(self, xyz):\n","        logit = F.softmax(self.m1(xyz), -1)\n","        logit = logit + F.softmax(self.m2(xyz), -1)\n","        return logit"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:17:53.197234Z","iopub.status.busy":"2023-04-18T02:17:53.196862Z","iopub.status.idle":"2023-04-18T02:17:53.238585Z","shell.execute_reply":"2023-04-18T02:17:53.237297Z","shell.execute_reply.started":"2023-04-18T02:17:53.197202Z"},"papermill":{"duration":5.530595,"end_time":"2023-04-17T09:26:14.301537","exception":false,"start_time":"2023-04-17T09:26:08.770942","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["1"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["final_net = FinalNet()\n","final_net.eval()\n","1"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:18:42.147071Z","iopub.status.busy":"2023-04-18T02:18:42.146652Z","iopub.status.idle":"2023-04-18T02:18:42.154002Z","shell.execute_reply":"2023-04-18T02:18:42.152464Z","shell.execute_reply.started":"2023-04-18T02:18:42.147030Z"},"papermill":{"duration":1.570924,"end_time":"2023-04-17T09:26:57.569018","exception":false,"start_time":"2023-04-17T09:26:55.998094","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import onnx\n","import onnx_tf\n","from onnx_tf.backend import prepare\n","import tensorflow as tf\n","import onnxsim\n"]},{"cell_type":"code","execution_count":11,"id":"5bc9a0f1","metadata":{},"outputs":[],"source":["# !pip install tensorflow_probability"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:18:42.155843Z","iopub.status.busy":"2023-04-18T02:18:42.155491Z","iopub.status.idle":"2023-04-18T02:18:42.169815Z","shell.execute_reply":"2023-04-18T02:18:42.168552Z","shell.execute_reply.started":"2023-04-18T02:18:42.155809Z"},"papermill":{"duration":0.014512,"end_time":"2023-04-17T09:26:57.591152","exception":false,"start_time":"2023-04-17T09:26:57.576640","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["max_length = 130 #1601"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:18:42.171852Z","iopub.status.busy":"2023-04-18T02:18:42.171475Z","iopub.status.idle":"2023-04-18T02:18:42.187865Z","shell.execute_reply":"2023-04-18T02:18:42.186527Z","shell.execute_reply.started":"2023-04-18T02:18:42.171815Z"},"papermill":{"duration":0.02158,"end_time":"2023-04-17T09:26:57.619582","exception":false,"start_time":"2023-04-17T09:26:57.598002","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class InputNet(tf.keras.layers.Layer):\n","    def __init__(self, ):\n","        super(InputNet, self).__init__()\n","        self.lip = tf.constant(SLIP)\n","        self.lhand = tf.constant(LHAND)\n","        self.rhand = tf.constant(RHAND)\n","        self.pose = tf.constant(SPOSE)\n","        self.reye = tf.constant(REYE)\n","        self.leye = tf.constant(LEYE)\n","        self.nose = tf.constant(NOSE)\n","        self.hand_start = tf.constant(HAND_START)\n","        self.hand_end = tf.constant(HAND_END)\n","        self.max_length = max_length\n","\n","    def call(self, xyz):\n","        #x = xyz\n","        xyz = xyz[:,:,:2]\n","        L = len(xyz)\n","        if L > self.max_length:\n","\n","            i = (L-self.max_length)//2\n","            xyz = xyz[i:i + self.max_length]  # center\n","\n","\n","        not_nan_xyz =  tf.reshape(xyz[~tf.math.is_nan(xyz)], (-1,2))\n","        xyz -= tf.math.reduce_mean (not_nan_xyz, axis=0, keepdims=True)   # noramlisation to common maen\n","        xyz /= tf.reduce_mean(tf.math.reduce_std (not_nan_xyz, axis=0, keepdims=True))\n","        \n","        x = tf.concat([\n","            tf.gather(xyz, self.lhand, axis=1),\n","            tf.gather(xyz, self.rhand, axis=1),\n","            tf.gather(xyz, self.lip, axis=1),\n","            tf.gather(xyz, self.pose, axis=1),\n","            tf.gather(xyz, self.reye, axis=1),\n","            tf.gather(xyz, self.leye, axis=1),\n","            tf.gather(xyz, self.nose, axis=1),\n","        ],1)\n","        return  x"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:18:42.190804Z","iopub.status.busy":"2023-04-18T02:18:42.190350Z","iopub.status.idle":"2023-04-18T02:18:42.216450Z","shell.execute_reply":"2023-04-18T02:18:42.215019Z","shell.execute_reply.started":"2023-04-18T02:18:42.190766Z"},"papermill":{"duration":0.027535,"end_time":"2023-04-17T09:26:57.654015","exception":false,"start_time":"2023-04-17T09:26:57.626480","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class FeatNet(nn.Module):\n","    def __init__(self, ):\n","        super().__init__()\n","        self.DIST_INDEX = DIST_INDEX\n","        self.LIP_DIST_INDEX = LIP_DIST_INDEX\n","        self.POSE_DIST_INDEX = POSE_DIST_INDEX\n","        self.EYE_DIST_INDEX = EYE_DIST_INDEX\n","  \n","    def forward(self, xyz):\n","        lhand = xyz[:, 0:21,:]#21\n","        rhand = xyz[:, 21:42,:]#21\n","        lip   = xyz[:, 42:62,:]#20\n","        pose = xyz[:, 62:70,:]#8\n","        reye = xyz[:, 70:78,:]#16\n","        leye = xyz[:, 78:86,:]#16\n","        nose = xyz[:, 86:90,:]#4\n","\n","\n","        x = torch.cat([xyz[1:,:len(LHAND+RHAND),:]-xyz[:-1,:len(LHAND+RHAND),:],torch.zeros((1,len(LHAND+RHAND),2))],0)\n","        \n","        ld = lhand[:,:,:2].reshape(-1,len(LHAND),1,2)-lhand[:,:,:2].reshape(-1,1,len(LHAND),2)\n","        ld = torch.sqrt((ld**2).sum(-1))\n","        ld = ld.reshape(-1,len(LHAND)*len(LHAND))[:,DIST_INDEX]\n","        \n","        rd = rhand[:,:,:2].reshape(-1,len(LHAND),1,2)-rhand[:,:,:2].reshape(-1,1,len(LHAND),2)\n","        rd = torch.sqrt((rd**2).sum(-1))\n","        rd = rd.reshape(-1,len(LHAND)*len(LHAND))[:,DIST_INDEX]\n","        \n","        lipd = lip[:,:,:2].reshape(-1,len(SLIP),1,2)-lip[:,:,:2].reshape(-1,1,len(SLIP),2)\n","        lipd = torch.sqrt((lipd**2).sum(-1))\n","        lipd = lipd.reshape(-1,len(SLIP)*len(SLIP))[:,LIP_DIST_INDEX]\n","        \n","        posed = pose[:,:,:2].reshape(-1,len(SPOSE),1,2)-pose[:,:,:2].reshape(-1,1,len(SPOSE),2)\n","        posed = torch.sqrt((posed**2).sum(-1))\n","        posed = posed.reshape(-1,len(SPOSE)*len(SPOSE))[:,POSE_DIST_INDEX]\n","        \n","        reyed = reye[:,:,:2].reshape(-1,len(REYE),1,2)-reye[:,:,:2].reshape(-1,1,len(REYE),2)\n","        reyed = torch.sqrt((reyed**2).sum(-1))\n","        reyed = reyed.reshape(-1,len(REYE)*len(REYE))[:,EYE_DIST_INDEX]\n","        \n","        leyed = leye[:,:,:2].reshape(-1,len(LEYE),1,2)-leye[:,:,:2].reshape(-1,1,len(LEYE),2)\n","        leyed = torch.sqrt((leyed**2).sum(-1))\n","        leyed = leyed.reshape(-1,len(LEYE)*len(LEYE))[:,EYE_DIST_INDEX]\n","\n","        dist_hand=torch.sqrt(((lhand-rhand)**2).sum(-1))\n","\n","        xyz = torch.cat([xyz.reshape(-1,(len(LHAND+RHAND+REYE+LEYE+NOSE+SLIP+SPOSE))*2), \n","                            x.reshape(-1,(len(LHAND+RHAND))*2),\n","                            ld,\n","                            rd,\n","                            lipd,\n","                            posed,\n","                            reyed,\n","                            leyed,\n","                            dist_hand,\n","                            ],1)\n","        \n","        xyz[torch.isnan(xyz)] = 0\n","            \n","        return xyz"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:18:42.219507Z","iopub.status.busy":"2023-04-18T02:18:42.218992Z","iopub.status.idle":"2023-04-18T02:18:42.234916Z","shell.execute_reply":"2023-04-18T02:18:42.233627Z","shell.execute_reply.started":"2023-04-18T02:18:42.219459Z"},"papermill":{"duration":0.017129,"end_time":"2023-04-17T09:26:57.678321","exception":false,"start_time":"2023-04-17T09:26:57.661192","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["FeatNet()"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["feat_net  = FeatNet()\n","feat_net.eval()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:18:42.240379Z","iopub.status.busy":"2023-04-18T02:18:42.239941Z","iopub.status.idle":"2023-04-18T02:20:07.234077Z","shell.execute_reply":"2023-04-18T02:20:07.232787Z","shell.execute_reply.started":"2023-04-18T02:18:42.240341Z"},"papermill":{"duration":38.224644,"end_time":"2023-04-17T09:27:35.910427","exception":false,"start_time":"2023-04-17T09:26:57.685783","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/zhouyuanzhe/anaconda3/envs/base2/lib/python3.8/site-packages/torch/onnx/utils.py:2029: UserWarning: Provided key output for dynamic axes is not a valid input/output name\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n","verbose: False, log level: Level.ERROR\n","======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n","\n","============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n","verbose: False, log level: Level.ERROR\n","======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n","\n","torch.onnx.export() passed !!\n","1\n","1\n","onnx simplify() passed !!\n","WARNING:tensorflow:From /home/zhouyuanzhe/anaconda3/envs/base2/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n","Instructions for updating:\n","Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"]},{"name":"stderr","output_type":"stream","text":["2023-05-03 11:11:02.455286: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-03 11:11:13.622900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9216 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5\n","2023-05-03 11:11:13.624454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6767 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5\n","2023-05-03 11:11:13.625858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 9256 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3d:00.0, compute capability: 7.5\n","2023-05-03 11:11:13.627203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 7651 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3e:00.0, compute capability: 7.5\n","2023-05-03 11:11:13.628624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 9256 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:88:00.0, compute capability: 7.5\n","2023-05-03 11:11:13.630006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 9256 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:89:00.0, compute capability: 7.5\n","2023-05-03 11:11:13.631380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 9256 MB memory:  -> device: 6, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:b1:00.0, compute capability: 7.5\n","2023-05-03 11:11:13.632770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 9256 MB memory:  -> device: 7, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:b2:00.0, compute capability: 7.5\n","WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: .//input_tf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: .//input_tf/assets\n","WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: .//single_tf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: .//single_tf/assets\n"]},{"name":"stdout","output_type":"stream","text":["tf_rep.export_graph() passed !!\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as input_net_layer_call_fn, input_net_layer_call_and_return_conditional_losses, restored_function_body, restored_function_body while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: .//tf/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: .//tf/assets\n"]},{"name":"stdout","output_type":"stream","text":["tf.saved_model() passed !!\n"]},{"name":"stderr","output_type":"stream","text":["2023-05-03 11:12:02.121073: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n","2023-05-03 11:12:02.121114: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n","2023-05-03 11:12:02.121813: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: .//tf\n","2023-05-03 11:12:02.153040: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n","2023-05-03 11:12:02.153078: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: .//tf\n","2023-05-03 11:12:02.232626: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n","2023-05-03 11:12:02.243335: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n","2023-05-03 11:12:02.439887: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: .//tf\n","2023-05-03 11:12:02.570253: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 448442 microseconds.\n","2023-05-03 11:12:02.892902: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"]},{"name":"stdout","output_type":"stream","text":["tflite convert() passed !!\n"]}],"source":["#pytorch to onnx to tflite\n","fold_dir = './'\n","if 1:\n","    \n","    name='model' \n","    input_onnx_file   = f'{fold_dir}/{name}.input.onnx'\n","    single_onnx_file  = f'{fold_dir}/{name}.single.onnx' \n","    input_tf_file    = f'{fold_dir}/input_tf'\n","    single_tf_file   = f'{fold_dir}/single_tf'\n","    tf_file     = f'{fold_dir}/tf'\n","    tflite_file = f'{fold_dir}/{name}.tflite'\n","\n","    def run_convert_onnx(): \n","        if 1:\n","            torch.onnx.export(\n","                feat_net,\n","                #torch.jit.script(input_net),\n","                #torch.jit.trace(input_net, torch.zeros(100,num_landmark,3)),          # model being run \n","                torch.zeros((100,90,2)), # model input (or a tuple for multiple inputs)\n","                input_onnx_file,             # where to save the model (can be a file or file-like object)\n","                export_params = True,        # store the trained parameter weights inside the model file\n","                opset_version = 12,          # the ONNX version to export the model to\n","                do_constant_folding=True,    # whether to execute constant folding for optimization \n","                input_names =  ['inputs'],    # the model's input names\n","                output_names = ['outputs'],   # the model's output names\n","                dynamic_axes={\n","                    'inputs': {0: 'length'},\n","                    'output': {0: 'length'},\n","                },\n","                #verbose = True,\n","            )\n","            torch.onnx.export(\n","                final_net,         \n","                #torch.jit.script(single_net),\n","                #torch.jit.trace(single_net, torch.zeros(max_length,82,3)),           \n","\n","                torch.zeros((max_length,point_dim)), \n","                single_onnx_file,             \n","                export_params = True,         \n","                opset_version = 12, \n","                do_constant_folding=True,      \n","                input_names =  ['inputs'],     \n","                output_names = ['outputs'],  \n","                dynamic_axes={\n","                    'inputs': {0: 'length'},\n","                },\n","                #verbose = True,\n","            )\n","            print('torch.onnx.export() passed !!')\n","\n","        if 1:\n","            for f in [input_onnx_file, single_onnx_file]:\n","                print(1)\n","                if f is None: continue\n","                model = onnx.load(f)\n","                onnx.checker.check_model(model)\n","                #model_simple, check = onnxsim.simplify(model)\n","                onnx.save(model, f)\n","            print('onnx simplify() passed !!')\n","\n","\n","    def run_convert_tflite():\n","        if 1:\n","            tf_rep = prepare(onnx.load(input_onnx_file))\n","            tf_rep.export_graph(input_tf_file) \n","            tf_rep = prepare(onnx.load(single_onnx_file))\n","            tf_rep.export_graph(single_tf_file) \n","            print('tf_rep.export_graph() passed !!')\n","\n","        if 1:\n","            class TFModel(tf.Module):\n","                def __init__(self):\n","                    super(TFModel, self).__init__()\n","                    #self.input  = tf.saved_model.load(input_tf_file)\n","                    self.input = InputNet()\n","                    self.feat = tf.saved_model.load(input_tf_file)\n","                    self.single = tf.saved_model.load(single_tf_file)\n","                    self.input.trainable = False\n","                    # self.single.trainable = False\n","\n","                @tf.function(input_signature=[\n","                    tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')\n","                ])\n","                def call(self, input):\n","                    y = {}\n","                    x = self.input(input)\n","                    x = self.feat(**{'inputs': x})['outputs']\n","                    y['outputs'] = self.single(**{'inputs': x})['outputs']\n","                    \n","                    return y\n","\n","            tfmodel = TFModel()\n","            tf.saved_model.save(tfmodel, tf_file, signatures={'serving_default': tfmodel.call})\n","            print('tf.saved_model() passed !!')\n","\n","        if 1:\n","            converter = tf.lite.TFLiteConverter.from_saved_model(tf_file)\n","            # converter.target_spec.supported_ops = [\n","            #     tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n","            #     tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n","            # ]\n","            #converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","            #converter.target_spec.supported_types = [tf.FLOAT16]\n","            #converter.allow_custom_ops = True\n","            #converter.experimental_new_converter = True \n","            converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","            converter.target_spec.supported_types = [tf.float16]\n","            tf_lite_model = converter.convert()\n","            with open(tflite_file, 'wb') as f:\n","                f.write(tf_lite_model)\n","            print('tflite convert() passed !!')\n"," \n","    run_convert_onnx()\n","    run_convert_tflite()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:20:08.390471Z","iopub.status.busy":"2023-04-18T02:20:08.390087Z","iopub.status.idle":"2023-04-18T02:20:09.764498Z","shell.execute_reply":"2023-04-18T02:20:09.762570Z","shell.execute_reply.started":"2023-04-18T02:20:08.390436Z"},"papermill":{"duration":2.943156,"end_time":"2023-04-17T09:27:38.860948","exception":false,"start_time":"2023-04-17T09:27:35.917792","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["updating: model.tflite (deflated 8%)\n"]}],"source":["!zip submission.zip  'model.tflite'\n","# !unzip -o submission.zip\n","# !ls"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:20:09.768017Z","iopub.status.busy":"2023-04-18T02:20:09.767109Z","iopub.status.idle":"2023-04-18T02:20:09.941701Z","shell.execute_reply":"2023-04-18T02:20:09.940566Z","shell.execute_reply.started":"2023-04-18T02:20:09.767947Z"},"papermill":{"duration":0.218768,"end_time":"2023-04-17T09:27:39.087704","exception":false,"start_time":"2023-04-17T09:27:38.868936","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_relevant_data_subset(pq_path):\n","    data_columns = ['x', 'y', 'z']\n","    data = pd.read_parquet(pq_path, columns=data_columns)\n","    n_frames = int(len(data) / 543)\n","    data = data.values.reshape(n_frames, 543, len(data_columns))\n","    return data.astype(np.float32)\n","\n","def read_dict(file_path):\n","    path = os.path.expanduser(file_path)\n","    with open(path, \"r\") as f:\n","        dic = json.load(f)\n","    return dic\n","\n","\n","train = pd.read_csv(f\"./train.csv\")\n","label_index = read_dict(f\"./sign_to_prediction_index_map.json\")\n","index_label = dict([(label_index[key], key) for key in label_index])"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:20:09.943844Z","iopub.status.busy":"2023-04-18T02:20:09.943384Z","iopub.status.idle":"2023-04-18T02:20:20.347232Z","shell.execute_reply":"2023-04-18T02:20:20.345894Z","shell.execute_reply.started":"2023-04-18T02:20:09.943798Z"},"papermill":{"duration":30.449797,"end_time":"2023-04-17T09:28:09.546515","exception":false,"start_time":"2023-04-17T09:27:39.096718","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 1741/2000 [01:31<00:15, 16.79it/s]"]}],"source":["%%time\n","import tflite_runtime.interpreter as tflite\n","interpreter = tflite.Interpreter('model.tflite')\n","found_signatures = list(interpreter.get_signature_list().keys())\n","prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n","\n","preds = []\n","labels = []\n","count = 0\n","N = 2000 #train.shape[0]\n","exclude_path = []\n","for i in tqdm(range(N)):\n","    frames = load_relevant_data_subset(f'./{train.iloc[i].path}')\n","    output = prediction_fn(inputs=frames)\n","\n","    sign = np.argmax(output[\"outputs\"])\n","    topk = np.argsort(output['outputs'])[0][-1:]\n","    label = label_index[train.iloc[i].sign]\n","    if label in topk:\n","        count += 1\n","    else:\n","        exclude_path.append(train.iloc[i].path)\n","\n","count/N\n","\n","\n","# 114"]},{"cell_type":"code","execution_count":null,"id":"eb26926c","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ebf3d0e8","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"8b99ede2","metadata":{},"outputs":[],"source":["# np.load('exclude.npy')"]},{"cell_type":"code","execution_count":null,"id":"2c68b4f5","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"dab70a79","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"92c82be7","metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax (1901384113.py, line 2)","output_type":"error","traceback":["\u001b[0;36m  Input \u001b[0;32mIn [524]\u001b[0;36m\u001b[0m\n\u001b[0;31m    CPU times: user 34.8 s, sys: 1.78 s, total: 36.6 s\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["# 4 head\n","CPU times: user 34.8 s, sys: 1.78 s, total: 36.6 s\n","Wall time: 36.8 s\n","\n","# 16head + view\n","CPU times: user 35.4 s, sys: 1.84 s, total: 37.2 s\n","Wall time: 37.6 s\n","\n","# 16 head\n","CPU times: user 34.4 s, sys: 1.66 s, total: 36.1 s\n","Wall time: 36.2 s"]},{"cell_type":"code","execution_count":null,"id":"80889ff6","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"639e2df0","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:20:20.349339Z","iopub.status.busy":"2023-04-18T02:20:20.348974Z","iopub.status.idle":"2023-04-18T02:20:20.355624Z","shell.execute_reply":"2023-04-18T02:20:20.354087Z","shell.execute_reply.started":"2023-04-18T02:20:20.349305Z"},"papermill":{"duration":0.024988,"end_time":"2023-04-17T09:28:09.588814","exception":false,"start_time":"2023-04-17T09:28:09.563826","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# print(output[\"outputs\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:20:20.358359Z","iopub.status.busy":"2023-04-18T02:20:20.357846Z","iopub.status.idle":"2023-04-18T02:20:20.366538Z","shell.execute_reply":"2023-04-18T02:20:20.365469Z","shell.execute_reply.started":"2023-04-18T02:20:20.358299Z"},"papermill":{"duration":0.027648,"end_time":"2023-04-17T09:28:09.633148","exception":false,"start_time":"2023-04-17T09:28:09.605500","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# %%time\n","# cnt=0\n","# for i in tqdm(range(400)):\n","#     frames = load_relevant_data_subset(f'/kaggle/input/asl-signs/{train.iloc[i].path}')\n","#     output = prediction_fn(inputs=frames)\n","#     sign = np.argmax(output[\"outputs\"])\n","#     print(f\"Predicted label: {index_label[sign]}, Actual Label: {train.iloc[i].sign}\")\n","#     if index_label[sign]!=train.iloc[i].sign:\n","#         cnt+=1\n","# print(cnt)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T02:20:20.368345Z","iopub.status.busy":"2023-04-18T02:20:20.367820Z","iopub.status.idle":"2023-04-18T02:20:20.386339Z","shell.execute_reply":"2023-04-18T02:20:20.384911Z","shell.execute_reply.started":"2023-04-18T02:20:20.368290Z"},"papermill":{"duration":0.027353,"end_time":"2023-04-17T09:28:09.677220","exception":false,"start_time":"2023-04-17T09:28:09.649867","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# [0.01085861 0.00581808 0.00685086 0.00304363 0.01479311 0.00817709\n","#  0.00340905 0.00318506 0.0233486  0.01050716 0.1883654  0.06354285\n","#  0.00429218 0.00845518 0.00856266 0.00674799 0.00605066 0.00663673\n","#  0.01101495 0.00473946 0.00718604 0.01581484 0.00979448 0.00933167\n","#  0.00909571 0.00761033 0.0079331  0.01132183 0.00546459 0.00705986\n","#  0.00446261 0.00805381 0.00862744 0.00863338 0.00812062 0.00676276\n","#  0.00807868 0.02296103 0.00857505 0.00721142 0.00628418 0.01281936\n","#  0.00548189 0.00735567 0.00574347 0.00762902 0.00878952 0.00886532\n","#  0.01273214 0.00704682 0.01344372 0.00995772 0.0073814  0.00659714\n","#  0.00734928 0.00888218 0.00814375 0.00859207 0.0080293  0.00954303\n","#  0.0176774  0.00564051 0.02074489 0.00685068 0.01218808 0.00627878\n","#  0.00417787 0.00859415 0.00817147 0.00301294 0.01126396 0.00508036\n","#  0.01058887 0.00715309 0.00879091 0.00931721 0.00505042 0.00747855\n","#  0.00890584 0.0099776  0.00793931 0.00610487 0.00978467 0.0113838\n","#  0.00602421 0.00689216 0.00653033 0.00553205 0.00650916 0.01165451\n","#  0.00894795 0.00780089 0.00688653 0.00819174 0.03024156 0.00330047\n","#  0.00574727 0.00616653 0.01027174 0.00659046 0.00588827 0.00415567\n","#  0.00988593 0.00802699 0.00456634 0.00853014 0.00969563 0.00664793\n","#  0.00753294 0.00557278 0.00765562 0.0061117  0.00961248 0.00826899\n","#  0.01247947 0.00554131 0.0138128  0.01092679 0.01032632 0.01741139\n","#  0.00958047 0.00666909 0.00370869 0.0104286  0.00786915 0.00149389\n","#  0.01268701 0.00562417 0.00593344 0.00859769 0.00469574 0.00894758\n","#  0.00675207 0.00438429 0.00722449 0.00883858 0.00632744 0.00602204\n","#  0.00777974 0.00490518 0.00606634 0.00746216 0.00522026 0.00602841\n","#  0.00656764 0.0111602  0.00662472 0.00631345 0.00751031 0.00889285\n","#  0.00786171 0.00789982 0.01060051 0.00874808 0.00476171 0.00731064\n","#  0.00933065 0.00540848 0.02670925 0.00531322 0.00992232 0.00717802\n","#  0.00599299 0.00933668 0.00482148 0.00589903 0.00574286 0.00494124\n","#  0.01233393 0.00907254 0.00595442 0.00576073 0.00596522 0.005933\n","#  0.00664493 0.00352007 0.00895852 0.00677059 0.01110536 0.00539469\n","#  0.00851405 0.01116983 0.00432136 0.00624733 0.00474382 0.00759205\n","#  0.01367113 0.00743047 0.00906641 0.00573219 0.00537325 0.01006344\n","#  0.00801374 0.00972718 0.00623355 0.00803888 0.00692571 0.00617468\n","#  0.00841703 0.00599053 0.00909205 0.01109888 0.01301423 0.00654494\n","#  0.01213645 0.00592066 0.00864201 0.00987625 0.00792791 0.00789566\n","#  0.0055953  0.00887042 0.0045177  0.00581646 0.00857393 0.00500618\n","#  0.00586388 0.00491259 0.0074577  0.00624605 0.0091049  0.10224412\n","#  0.00682174 0.0088692  0.00820932 0.00832468 0.00531415 0.0089981\n","#  0.00428656 0.00630823 0.02486216 0.00903836 0.00734655 0.06334254\n","#  0.00587949 0.00601918 0.00598095 0.00721327 0.00662056 0.02103801\n","#  0.0051178  0.01425657 0.00883084 0.00373367 0.0118778  0.5697484\n","#  0.01081768 0.00919196 0.00815717 0.00522287]"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.019429,"end_time":"2023-04-17T09:28:09.715133","exception":false,"start_time":"2023-04-17T09:28:09.695704","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.019249,"end_time":"2023-04-17T09:28:09.754054","exception":false,"start_time":"2023-04-17T09:28:09.734805","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.13 ('base2': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"papermill":{"default_parameters":{},"duration":145.926207,"end_time":"2023-04-17T09:28:13.272304","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-04-17T09:25:47.346097","version":"2.4.0"},"vscode":{"interpreter":{"hash":"37bd31f29216d03bfa1930631652512776ac4fb60975d721c6b44f5541cbd062"}}},"nbformat":4,"nbformat_minor":5}
